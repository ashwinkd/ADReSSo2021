{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FineTuneLOOCV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMC6TVOAUgu107iBbLgBuQj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "49a3273273ca45648c3df34c637e3f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f3ff2b825a2444428b15ac0a5209ad64",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cf7ead1d685c4aa7b47c0987c7ed56f2",
              "IPY_MODEL_b8f36ad7ea1a4ed9b1c7dbcbd94ac6f9"
            ]
          }
        },
        "f3ff2b825a2444428b15ac0a5209ad64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf7ead1d685c4aa7b47c0987c7ed56f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4737ea9d418c4658a3c628bd521f7ec4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cef92f91638f455cbb32dd14e8afd33a"
          }
        },
        "b8f36ad7ea1a4ed9b1c7dbcbd94ac6f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_70bdd3ac9fba40ab942e7a110a8a9cfd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:02&lt;00:00, 114kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_447f60ed708846a98e25177cd4f93e50"
          }
        },
        "4737ea9d418c4658a3c628bd521f7ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cef92f91638f455cbb32dd14e8afd33a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70bdd3ac9fba40ab942e7a110a8a9cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "447f60ed708846a98e25177cd4f93e50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d1b5d1aa6c448f8bfe893cfacd6a350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cb4f283ef9024b54aad731311237ccc3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_189dfb4180174c85b4b2480a6f60f9ff",
              "IPY_MODEL_df39bfe78a9c4518b653d139817c4a93"
            ]
          }
        },
        "cb4f283ef9024b54aad731311237ccc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "189dfb4180174c85b4b2480a6f60f9ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_98b95f2ce1d546e4a3e5420051e99da2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_48b5246a2bee4786b45c08b40eac2915"
          }
        },
        "df39bfe78a9c4518b653d139817c4a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_96759adaff67447b846f344a9dd0b764",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 35.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6efe851749314e97898e17b3e2462156"
          }
        },
        "98b95f2ce1d546e4a3e5420051e99da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48b5246a2bee4786b45c08b40eac2915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96759adaff67447b846f344a9dd0b764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6efe851749314e97898e17b3e2462156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba11f0556103456c975afb47b7aea483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_057a6361921b4ff48f0a81686c18bf0e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b9f5859c4fe64a18bd48ddf71e668673",
              "IPY_MODEL_6e29e8501af1435eb740875b4b50ff5b"
            ]
          }
        },
        "057a6361921b4ff48f0a81686c18bf0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9f5859c4fe64a18bd48ddf71e668673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_89dbbba1ac894649a86d560a5b94c4d3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c02b2d077aa4a6ca7e01b247d186e01"
          }
        },
        "6e29e8501af1435eb740875b4b50ff5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dd128a4a3189424dbd93f87951bdf3c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 1.36MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee23bc4953e6418c91a4e95991f3922f"
          }
        },
        "89dbbba1ac894649a86d560a5b94c4d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c02b2d077aa4a6ca7e01b247d186e01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd128a4a3189424dbd93f87951bdf3c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee23bc4953e6418c91a4e95991f3922f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0d3893c564e4f4083c78f1d0d6ab98e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_53e763afafbb4f70a7038f037f255714",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fdc355a4428446b9ac3287c2789dc600",
              "IPY_MODEL_68b63d880dc64330a53975b7c3134434"
            ]
          }
        },
        "53e763afafbb4f70a7038f037f255714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fdc355a4428446b9ac3287c2789dc600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3a2420af4cf44e759f9d6e9073138d88",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14bdae2473f3422d885f4fa877d8521c"
          }
        },
        "68b63d880dc64330a53975b7c3134434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3b48c35ad4fe44d5acc9e6f455370f25",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:12&lt;00:00, 46.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a986ed434cf4d448ba156a7694cc0f0"
          }
        },
        "3a2420af4cf44e759f9d6e9073138d88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14bdae2473f3422d885f4fa877d8521c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b48c35ad4fe44d5acc9e6f455370f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a986ed434cf4d448ba156a7694cc0f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22e20d8455964b9ab034dafcb580acc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1d37e6864aa4442d88875a5e679e2da8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5db33ca3fd83434f84760b5809823efc",
              "IPY_MODEL_c64ce4ca7abe4982aa7436c8b86f3209"
            ]
          }
        },
        "1d37e6864aa4442d88875a5e679e2da8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5db33ca3fd83434f84760b5809823efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_836cc44d60f545a988e5e3ce12b18941",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7730d5d57ba43599e1a422a85c71433"
          }
        },
        "c64ce4ca7abe4982aa7436c8b86f3209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_82aaab8b68db4f5c9559f4b751af0d7a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 47.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35ed2e77cfbc49b1b933c25a7dc3b623"
          }
        },
        "836cc44d60f545a988e5e3ce12b18941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7730d5d57ba43599e1a422a85c71433": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82aaab8b68db4f5c9559f4b751af0d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35ed2e77cfbc49b1b933c25a7dc3b623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashwinkd/ADReSSo2021/blob/master/FineTuneLOOCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8HlwwyCPJSX",
        "outputId": "8f4c69b4-b4b4-462d-b079-34392b25223c"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.1MB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 32.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5eq2FbbxUkH",
        "outputId": "e925c06d-efba-4aec-dbe1-0d4f3a8f9b7d"
      },
      "source": [
        "# models = ['Bert', 'Roberta', 'DistilBERT']\n",
        "# _ = [print(f\"[{i + 1}] {m}\") for i, m in enumerate(models)]\n",
        "# model_num = int(input(\"Choose model: \")) - 1\n",
        "# if model_num not in range(len(models)):\n",
        "#     raise Exception(\"Incorrect model chosen.\")\n",
        "\n",
        "# model_name = models[model_num]\n",
        "#####################################################################\n",
        "import random\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from google.colab import drive\n",
        "import datetime\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "import time\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "from sklearn.model_selection import KFold\n",
        "import pickle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#################### Global Variables ####################\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "UNUSED_TOKEN = {1: '[unused0]',\n",
        "                2: '[unused1]',\n",
        "                3: '[unused2]'}\n",
        "to_categorical = {'cn': 0,\n",
        "                  'ad': 1}\n",
        "\n",
        "#################### Read Data ####################\n",
        "\n",
        "df = pd.read_pickle('/content/drive/MyDrive/Research/ADReSSo/data.pickle')\n",
        "df.dx = df.dx.apply(lambda x: to_categorical[x])\n",
        "\n",
        "#################### Train and Test Sets ####################\n",
        "\n",
        "# train_text, temp_text, train_labels, temp_labels = train_test_split(df['transcript'], df['dx'],\n",
        "#                                                                     random_state=seed_val,\n",
        "#                                                                     test_size=0.3,\n",
        "#                                                                     stratify=df['dx'])\n",
        "\n",
        "\n",
        "#################### BERT features ####################\n",
        "\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def get_bert_tokenizer():\n",
        "    from transformers import BertTokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    return tokenizer\n",
        "\n",
        "\n",
        "def get_roberta_tokenizer():\n",
        "    from transformers import RobertaTokenizer\n",
        "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "    return tokenizer\n",
        "\n",
        "def get_distilbert_tokenizer():\n",
        "    from transformers import DistilBertTokenizer\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "    return tokenizer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def encode_sentence(transcript, tokenizer):\n",
        "    tokens = []\n",
        "    continous_speech = re.split(r'\\[P\\d\\]', transcript)\n",
        "    if not continous_speech:\n",
        "        transcript = str.encode(transcript, 'utf-8')\n",
        "        tokens = list(tokenizer.tokenize(transcript))\n",
        "    else:\n",
        "        for idx, speech in enumerate(continous_speech):\n",
        "            tokens += list(tokenizer.tokenize(speech))\n",
        "            if idx + 1 < len(continous_speech):\n",
        "                surrounding_speech = r'{}\\[P\\d\\]{}'.format(continous_speech[idx], continous_speech[idx + 1])\n",
        "                surrounding_speech = re.findall(surrounding_speech, transcript)[0]\n",
        "                pause_num = int(re.sub('[^0-9]', '', surrounding_speech))\n",
        "                tokens.append(UNUSED_TOKEN[pause_num])\n",
        "    tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    return token_ids\n",
        "\n",
        "\n",
        "def add_padding(input_word_ids, max_seq_len):\n",
        "    input_type = []\n",
        "    for idx, embedding in enumerate(input_word_ids):\n",
        "        embedding_len = len(embedding)\n",
        "        e_input_type = np.ones(embedding_len, dtype=np.int64).tolist()\n",
        "        if embedding_len < max_seq_len:\n",
        "            zeros = np.zeros(max_seq_len - embedding_len, dtype=np.int64).tolist()\n",
        "            e_input_type += zeros\n",
        "            embedding += zeros\n",
        "        elif embedding_len > max_seq_len:\n",
        "            embedding = embedding[:max_seq_len - 1] + [102]\n",
        "            e_input_type = e_input_type[:max_seq_len]\n",
        "        input_type.append(torch.tensor([e_input_type]))\n",
        "        input_word_ids[idx] = torch.tensor([embedding])\n",
        "    return {'input_ids': input_word_ids, 'attention_mask': input_type}\n",
        "\n",
        "\n",
        "def bert_encode(transcripts, tokenizer, max_seq_len):\n",
        "    input_word_ids = [encode_sentence(s, tokenizer)\n",
        "                      for s in transcripts]\n",
        "    input_word_ids = add_padding(input_word_ids, max_seq_len)\n",
        "    return input_word_ids\n",
        "############################# Models ##################################\n",
        "def get_bert_model():\n",
        "    from transformers import BertForSequenceClassification\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        \"bert-base-uncased\",  # Use the 12-layer BERT model, with an uncased vocab.\n",
        "        num_labels=2,  # The number of output labels--2 for binary classification.\n",
        "        # You can increase this for multi-class tasks.\n",
        "        output_attentions=False,  # Whether the model returns attentions weights.\n",
        "        output_hidden_states=False,  # Whether the model returns all hidden-states.\n",
        "    )\n",
        "    model.cuda()\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_roberta_model():\n",
        "    from transformers import RobertaForSequenceClassification\n",
        "    model = RobertaForSequenceClassification.from_pretrained(\n",
        "        \"roberta-base\",  # Use the 12-layer BERT model, with an uncased vocab.\n",
        "        num_labels=2,  # The number of output labels--2 for binary classification.\n",
        "        # You can increase this for multi-class tasks.\n",
        "        output_attentions=False,  # Whether the model returns attentions weights.\n",
        "        output_hidden_states=False,  # Whether the model returns all hidden-states.\n",
        "    )\n",
        "    model.cuda()\n",
        "    return model\n",
        "\n",
        "def get_distilbert_model():\n",
        "    from transformers import DistilBertForSequenceClassification\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(\n",
        "        \"distilbert-base-uncased\",  # Use the 12-layer BERT model, with an uncased vocab.\n",
        "        num_labels=2,  # The number of output labels--2 for binary classification.\n",
        "        # You can increase this for multi-class tasks.\n",
        "        output_attentions=False,  # Whether the model returns attentions weights.\n",
        "        output_hidden_states=False,  # Whether the model returns all hidden-states.\n",
        "    )\n",
        "    model.cuda()\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "49a3273273ca45648c3df34c637e3f77",
            "f3ff2b825a2444428b15ac0a5209ad64",
            "cf7ead1d685c4aa7b47c0987c7ed56f2",
            "b8f36ad7ea1a4ed9b1c7dbcbd94ac6f9",
            "4737ea9d418c4658a3c628bd521f7ec4",
            "cef92f91638f455cbb32dd14e8afd33a",
            "70bdd3ac9fba40ab942e7a110a8a9cfd",
            "447f60ed708846a98e25177cd4f93e50",
            "2d1b5d1aa6c448f8bfe893cfacd6a350",
            "cb4f283ef9024b54aad731311237ccc3",
            "189dfb4180174c85b4b2480a6f60f9ff",
            "df39bfe78a9c4518b653d139817c4a93",
            "98b95f2ce1d546e4a3e5420051e99da2",
            "48b5246a2bee4786b45c08b40eac2915",
            "96759adaff67447b846f344a9dd0b764",
            "6efe851749314e97898e17b3e2462156",
            "ba11f0556103456c975afb47b7aea483",
            "057a6361921b4ff48f0a81686c18bf0e",
            "b9f5859c4fe64a18bd48ddf71e668673",
            "6e29e8501af1435eb740875b4b50ff5b",
            "89dbbba1ac894649a86d560a5b94c4d3",
            "3c02b2d077aa4a6ca7e01b247d186e01",
            "dd128a4a3189424dbd93f87951bdf3c5",
            "ee23bc4953e6418c91a4e95991f3922f",
            "d0d3893c564e4f4083c78f1d0d6ab98e",
            "53e763afafbb4f70a7038f037f255714",
            "fdc355a4428446b9ac3287c2789dc600",
            "68b63d880dc64330a53975b7c3134434",
            "3a2420af4cf44e759f9d6e9073138d88",
            "14bdae2473f3422d885f4fa877d8521c",
            "3b48c35ad4fe44d5acc9e6f455370f25",
            "6a986ed434cf4d448ba156a7694cc0f0",
            "22e20d8455964b9ab034dafcb580acc3",
            "1d37e6864aa4442d88875a5e679e2da8",
            "5db33ca3fd83434f84760b5809823efc",
            "c64ce4ca7abe4982aa7436c8b86f3209",
            "836cc44d60f545a988e5e3ce12b18941",
            "e7730d5d57ba43599e1a422a85c71433",
            "82aaab8b68db4f5c9559f4b751af0d7a",
            "35ed2e77cfbc49b1b933c25a7dc3b623"
          ]
        },
        "id": "PbF4kWxnIbU6",
        "outputId": "f2b42876-b450-4b7a-f6a9-be7f4073e496"
      },
      "source": [
        "random_states = [0, 42, 2018, 56, 271, 27]\n",
        "models = ['Bert', 'Roberta', 'DistilBERT']\n",
        "batch_sizes = [8, 16, 32, 64]\n",
        "learning_rates = [5e-5, 3e-5, 2e-5]\n",
        "max_seq_lens = [64, 128, 256, 512]\n",
        "epochses = [1,2,3,4]\n",
        "loo = LeaveOneOut()\n",
        "params = [models, learning_rates, max_seq_lens, epochses, batch_sizes, batch_sizes, random_states]\n",
        "\n",
        "X = df.transcript.to_numpy()\n",
        "y = df.dx.to_numpy()\n",
        "best_params = None\n",
        "best_f1 = 0\n",
        "\n",
        "for param_list in list(itertools.product(*params)):\n",
        "    try:\n",
        "        model_name, lr, max_seq_len, epochs, batch_size_tr, batch_size_ts, seed_val = param_list\n",
        "        pred = []\n",
        "        target = []\n",
        "        print(f\"SEED: {seed_val}\\nMODEL: {model_name}\\nBATCH SIZE TR: {batch_size_tr}\\nBATCH SIZE TS: {batch_size_ts}\\nLEARNING RATE: {lr}\\nEMBEDDING LEN: {max_seq_len}\\nEPOCH: {epochs}\")\n",
        "        tokenizer = locals()[f\"get_{model_name.lower()}_tokenizer\"]()\n",
        "        model = locals()[f\"get_{model_name.lower()}_model\"]()\n",
        "        total_val_acc = []\n",
        "        total_val_f1 = []\n",
        "        random.seed(seed_val)\n",
        "        np.random.seed(seed_val)\n",
        "        torch.manual_seed(seed_val)\n",
        "        torch.cuda.manual_seed_all(seed_val)\n",
        "        for train_index, test_index in loo.split(X):\n",
        "            train_text, temp_text = X[train_index], X[test_index]\n",
        "            train_labels, temp_labels = y[train_index], y[test_index]\n",
        "\n",
        "            ########################################################################\n",
        "            #                           Data\n",
        "            ########################################################################                                   \n",
        "            tokens_train = bert_encode(train_text.tolist(), tokenizer, max_seq_len)\n",
        "            tokens_test = bert_encode(temp_text.tolist(), tokenizer, max_seq_len)\n",
        "\n",
        "            #################### Torch Dataset ####################\n",
        "\n",
        "            input_ids = torch.cat(tokens_train['input_ids'], dim=0)\n",
        "            attention_masks = torch.cat(tokens_train['attention_mask'], dim=0)\n",
        "            labels = torch.tensor(train_labels.tolist())\n",
        "\n",
        "            input_ids_test = torch.cat(tokens_test['input_ids'], dim=0)\n",
        "            attention_masks_test = torch.cat(tokens_test['attention_mask'], dim=0)\n",
        "            labels_test = torch.tensor(temp_labels.tolist())\n",
        "\n",
        "            ####################\n",
        "            dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "            train_size = int(0.9 * len(dataset))\n",
        "            val_size = len(dataset) - train_size\n",
        "            train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "            ####################\n",
        "            train_dataloader = DataLoader(\n",
        "                train_dataset,  # The training samples.\n",
        "                sampler=RandomSampler(train_dataset),  # Select batches randomly\n",
        "                batch_size=batch_size_tr  # Trains with this batch size.\n",
        "            )\n",
        "\n",
        "            validation_dataloader = DataLoader(\n",
        "                val_dataset,  # The validation samples.\n",
        "                sampler=SequentialSampler(val_dataset),  # Pull out batches sequentially.\n",
        "                batch_size=batch_size_tr  # Evaluate with this batch size.\n",
        "            )\n",
        "            ###############################################################################\n",
        "\n",
        "            total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "            #################### Training stuff ####################\n",
        "            optimizer = AdamW(model.parameters(),\n",
        "                            lr=lr,  # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                            eps=1e-8  # args.adam_epsilon  - default is 1e-8.\n",
        "                            )\n",
        "\n",
        "            scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                        num_warmup_steps=0,  # Default value in run_glue.py\n",
        "                                                        num_training_steps=total_steps)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            training_stats = []\n",
        "\n",
        "            # Measure the total training time for the whole run.\n",
        "            total_t0 = time.time()\n",
        "\n",
        "            # For each epoch...\n",
        "            for epoch_i in range(0, epochs):\n",
        "\n",
        "                # ========================================\n",
        "                #               Training\n",
        "                # ========================================\n",
        "\n",
        "                # Perform one full pass over the training set.\n",
        "\n",
        "                # print(\"\")\n",
        "                # print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "                # print('Training...')\n",
        "\n",
        "                # Measure how long the training epoch takes.\n",
        "                t0 = time.time()\n",
        "\n",
        "                # Reset the total loss for this epoch.\n",
        "                total_train_loss = 0\n",
        "\n",
        "                # Put the model into training mode. Don't be mislead--the call to\n",
        "                # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "                # `dropout` and `batchnorm` layers behave differently during training\n",
        "                # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "                model.train()\n",
        "\n",
        "                # For each batch of training data...\n",
        "                for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "                    # Progress update every 40 batches.\n",
        "                    if step % 40 == 0 and not step == 0:\n",
        "                        # Calculate elapsed time in minutes.\n",
        "                        elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                        # Report progress.\n",
        "                        # print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "                    # Unpack this training batch from our dataloader.\n",
        "                    #\n",
        "                    # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
        "                    # `to` method.\n",
        "                    #\n",
        "                    # `batch` contains three pytorch tensors:\n",
        "                    #   [0]: input ids\n",
        "                    #   [1]: attention masks\n",
        "                    #   [2]: labels\n",
        "                    b_input_ids = batch[0].to(device)\n",
        "                    b_input_mask = batch[1].to(device)\n",
        "                    b_labels = batch[2].to(device)\n",
        "\n",
        "                    # Always clear any previously calculated gradients before performing a\n",
        "                    # backward pass. PyTorch doesn't do this automatically because\n",
        "                    # accumulating the gradients is \"convenient while training RNNs\".\n",
        "                    # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "                    model.zero_grad()\n",
        "\n",
        "                    # Perform a forward pass (evaluate the model on this training batch).\n",
        "                    # In PyTorch, calling `model` will in turn call the model's `forward`\n",
        "                    # function and pass down the arguments. The `forward` function is\n",
        "                    # documented here:\n",
        "                    # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "                    # The results are returned in a results object, documented here:\n",
        "                    # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "                    # Specifically, we'll get the loss (because we provided labels) and the\n",
        "                    # \"logits\"--the model outputs prior to activation.\n",
        "                    try:\n",
        "                        result = model(b_input_ids,\n",
        "                                    token_type_ids=None,\n",
        "                                    attention_mask=b_input_mask,\n",
        "                                    labels=b_labels,\n",
        "                                    return_dict=True)\n",
        "                    except:\n",
        "                        result = model(b_input_ids,\n",
        "                                        #    token_type_ids=None,\n",
        "                                        attention_mask=b_input_mask,\n",
        "                                        labels=b_labels,\n",
        "                                        return_dict=True)                    \n",
        "\n",
        "                    loss = result.loss\n",
        "                    logits = result.logits\n",
        "\n",
        "                    # Accumulate the training loss over all of the batches so that we can\n",
        "                    # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "                    # single value; the `.item()` function just returns the Python value\n",
        "                    # from the tensor.\n",
        "                    total_train_loss += loss.item()\n",
        "\n",
        "                    # Perform a backward pass to calculate the gradients.\n",
        "                    loss.backward()\n",
        "\n",
        "                    # Clip the norm of the gradients to 1.0.\n",
        "                    # This is to help prevent the \"exploding gradients\" problem.\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "                    # Update parameters and take a step using the computed gradient.\n",
        "                    # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "                    # modified based on their gradients, the learning rate, etc.\n",
        "                    optimizer.step()\n",
        "\n",
        "                    # Update the learning rate.\n",
        "                    scheduler.step()\n",
        "\n",
        "                # Calculate the average loss over all of the batches.\n",
        "                avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "                # Measure how long this epoch took.\n",
        "                training_time = format_time(time.time() - t0)\n",
        "\n",
        "                # print(\"\")\n",
        "                # print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "                # print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "                # ========================================\n",
        "                #               Validation\n",
        "                # ========================================\n",
        "                # After the completion of each training epoch, measure our performance on\n",
        "                # our validation set.\n",
        "\n",
        "                # print(\"\")\n",
        "                # print(\"Running Validation...\")\n",
        "\n",
        "                t0 = time.time()\n",
        "\n",
        "                # Put the model in evaluation mode--the dropout layers behave differently\n",
        "                # during evaluation.\n",
        "                model.eval()\n",
        "\n",
        "                # Tracking variables\n",
        "                total_eval_accuracy = 0\n",
        "                total_eval_loss = 0\n",
        "                nb_eval_steps = 0\n",
        "\n",
        "                # Evaluate data for one epoch\n",
        "                for batch in validation_dataloader:\n",
        "                    # Unpack this training batch from our dataloader.\n",
        "                    #\n",
        "                    # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
        "                    # the `to` method.\n",
        "                    #\n",
        "                    # `batch` contains three pytorch tensors:\n",
        "                    #   [0]: input ids\n",
        "                    #   [1]: attention masks\n",
        "                    #   [2]: labels\n",
        "                    b_input_ids = batch[0].to(device)\n",
        "                    b_input_mask = batch[1].to(device)\n",
        "                    b_labels = batch[2].to(device)\n",
        "\n",
        "                    # Tell pytorch not to bother with constructing the compute graph during\n",
        "                    # the forward pass, since this is only needed for backprop (training).\n",
        "                    with torch.no_grad():\n",
        "                        # Forward pass, calculate logit predictions.\n",
        "                        # token_type_ids is the same as the \"segment ids\", which\n",
        "                        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                        result = model(b_input_ids,\n",
        "                                    #    token_type_ids=None,\n",
        "                                    attention_mask=b_input_mask,\n",
        "                                    labels=b_labels,\n",
        "                                    return_dict=True)\n",
        "\n",
        "                    # Get the loss and \"logits\" output by the model. The \"logits\" are the\n",
        "                    # output values prior to applying an activation function like the\n",
        "                    # softmax.\n",
        "                    loss = result.loss\n",
        "                    logits = result.logits\n",
        "\n",
        "                    # Accumulate the validation loss.\n",
        "                    total_eval_loss += loss.item()\n",
        "\n",
        "                    # Move logits and labels to CPU\n",
        "                    logits = logits.detach().cpu().numpy()\n",
        "                    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "                    # Calculate the accuracy for this batch of test sentences, and\n",
        "                    # accumulate it over all batches.\n",
        "                    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "                # Report the final accuracy for this validation run.\n",
        "                avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "                print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "                # Calculate the average loss over all of the batches.\n",
        "                avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "                # Measure how long the validation run took.\n",
        "                validation_time = format_time(time.time() - t0)\n",
        "\n",
        "                print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "                # print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "                # Record all statistics from this epoch.\n",
        "                training_stats.append(\n",
        "                    {\n",
        "                        'epoch': epoch_i + 1,\n",
        "                        'Training Loss': avg_train_loss,\n",
        "                        'Valid. Loss': avg_val_loss,\n",
        "                        'Valid. Accur.': avg_val_accuracy,\n",
        "                        'Training Time': training_time,\n",
        "                        'Validation Time': validation_time\n",
        "                    }\n",
        "                )\n",
        "\n",
        "            # print(\"\")\n",
        "            # print(\"Training complete!\")\n",
        "\n",
        "            # print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))\n",
        "\n",
        "            # Create the DataLoader.\n",
        "            prediction_data = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
        "            prediction_sampler = SequentialSampler(prediction_data)\n",
        "            prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size_ts)\n",
        "            ################################################################################\n",
        "            # Prediction on test set\n",
        "\n",
        "            # print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "            # Put model in evaluation mode\n",
        "            model.eval()\n",
        "\n",
        "            # Tracking variables \n",
        "            predictions , true_labels = [], []\n",
        "\n",
        "            # Predict \n",
        "            for batch in prediction_dataloader:\n",
        "                # Add batch to GPU\n",
        "                batch = tuple(t.to(device) for t in batch)\n",
        "            \n",
        "                # Unpack the inputs from our dataloader\n",
        "                b_input_ids, b_input_mask, b_labels = batch\n",
        "                \n",
        "                # Telling the model not to compute or store gradients, saving memory and \n",
        "                # speeding up prediction\n",
        "                with torch.no_grad():\n",
        "\n",
        "                    # Forward pass, calculate logit predictions.\n",
        "                    try:\n",
        "                        result = model(b_input_ids, \n",
        "                                        token_type_ids=None, \n",
        "                                        attention_mask=b_input_mask,\n",
        "                                        return_dict=True)\n",
        "                    except:\n",
        "                        result = model(b_input_ids, \n",
        "                                        #  token_type_ids=None, \n",
        "                                        attention_mask=b_input_mask,\n",
        "                                        return_dict=True)\n",
        "\n",
        "                logits = result.logits\n",
        "\n",
        "                # Move logits and labels to CPU\n",
        "                logits = logits.detach().cpu().numpy()\n",
        "                label_ids = b_labels.to('cpu').numpy()\n",
        "                \n",
        "                # Store predictions and true labels\n",
        "                predictions.append(logits)\n",
        "                true_labels.append(label_ids)\n",
        "\n",
        "            # print('    DONE.')\n",
        "            ###############################################################################\n",
        "            \n",
        "            f1_set = []\n",
        "            acc_set = []\n",
        "\n",
        "            # Evaluate each test batch using Matthew's correlation coefficient\n",
        "            # print('Calculating Acc and F1 Corr. Coef. for each batch...')\n",
        "\n",
        "            # For each input batch...\n",
        "            for i in range(len(true_labels)):\n",
        "                # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "                # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "                # in to a list of 0s and 1s.\n",
        "                pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "                \n",
        "                # Calculate and store the acc for this batch.\n",
        "                acc = accuracy_score(true_labels[i], pred_labels_i)          \n",
        "                acc_set.append(acc)\n",
        "\n",
        "                f1 = f1_score(true_labels[i], pred_labels_i)          \n",
        "                f1_set.append(f1)\n",
        "                pred += pred_labels_i\n",
        "                target += true_labels[i]\n",
        "                #############################################################################\n",
        "                # Create a barplot showing the Accuracy score for each batch of test samples.\n",
        "            \n",
        "            print(f\"Acc: {np.mean(acc_set)}\\tF1: {np.mean(f1_set)}\")\n",
        "            total_val_acc += acc_set\n",
        "            total_val_f1 += f1_set\n",
        "        print(\"\\n\\n\")\n",
        "        print(\"AVG Acc: {}\".format(np.mean(total_val_acc)))\n",
        "        print(\"AVG F1: {}\".format(np.mean(total_val_f1)))\n",
        "        print(\"Confusion Matrix: \\n\")\n",
        "        print(confusion_matrix(target, pred))\n",
        "        print(\"Total Acc: \", accuracy_score(target, pred) )\n",
        "        print(\"Total F1: \", f1_score(target, pred) )\n",
        "        if np.mean(total_val_f1) > best_f1:\n",
        "            print(\"#\"*40)\n",
        "            print(\"Best F1: \", param_list)\n",
        "            print(np.mean(total_val_f1))\n",
        "            best_f1 = \n",
        "            best_params = param_list\n",
        "            bparams = dict(zip([\"seed_val\", \"model_name\", \"batch_size_tr\", \"batch_size_ts\", \"lr\", \"max_seq_len\", \"epochs\"], best_params))\n",
        "            with open(\"/content/drive/MyDrive/Research/ADReSSo/best_params.pickle\", \"wb\") as fptr:\n",
        "                pickle.dump(bparams, fptr)\n",
        "                fptr.close()\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "print(bparams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49a3273273ca45648c3df34c637e3f77",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d1b5d1aa6c448f8bfe893cfacd6a350",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba11f0556103456c975afb47b7aea483",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0d3893c564e4f4083c78f1d0d6ab98e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22e20d8455964b9ab034dafcb580acc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.69\n",
            "Acc: 0.78125\tF1: 0.5952380952380952\n",
            "  Accuracy: 0.70\n",
            "  Validation Loss: 0.64\n",
            "Acc: 0.59375\tF1: 0.4807692307692307\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.61\n",
            "Acc: 0.78125\tF1: 0.6565934065934066\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.55\n",
            "Acc: 0.75\tF1: 0.6089743589743589\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.59\n",
            "Acc: 0.6785714285714286\tF1: 0.358974358974359\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.7169642857142857\n",
            "AVG F1: 0.5401098901098901\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.66\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.66\n",
            "Acc: 0.59375\tF1: 0.6006493506493507\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.49\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.39\n",
            "Acc: 0.6875\tF1: 0.32539682539682535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.45\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.36\n",
            "Acc: 0.9375\tF1: 0.7166666666666667\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.23\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.18\n",
            "Acc: 0.90625\tF1: 0.7333333333333334\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.33\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "Acc: 0.9375\tF1: 0.7166666666666667\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.8125\n",
            "AVG F1: 0.6185425685425686\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.70\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.65\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.51\n",
            "Acc: 0.625\tF1: 0.3333333333333333\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.47\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.30\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.37\n",
            "Acc: 0.71875\tF1: 0.4606060606060606\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.53\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.72\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.81\n",
            "Acc: 0.9375\tF1: 0.75\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.12\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.18\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.20\n",
            "Acc: 0.90625\tF1: 0.7333333333333334\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 0.9642857142857143\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.8303571428571429\n",
            "AVG F1: 0.6054545454545455\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.72\n",
            "  Accuracy: 0.49\n",
            "  Validation Loss: 0.69\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.69\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.69\n",
            "Acc: 0.59375\tF1: 0.6363636363636364\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.43\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.33\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.29\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.42\n",
            "Acc: 0.6875\tF1: 0.3392857142857143\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.32\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.52\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.85\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.83\n",
            "Acc: 0.90625\tF1: 0.7142857142857143\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.35\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.08\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.12\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.28\n",
            "Acc: 1.0\tF1: 0.75\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.91\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.8375\n",
            "AVG F1: 0.637987012987013\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.66\n",
            "Acc: 0.5\tF1: 0.225\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.57\n",
            "Acc: 0.65625\tF1: 0.35833333333333334\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.58\n",
            "Acc: 0.75\tF1: 0.625\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.57\n",
            "Acc: 0.84375\tF1: 0.6976190476190476\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.73\n",
            "Acc: 0.8392857142857143\tF1: 0.4666666666666667\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.7178571428571429\n",
            "AVG F1: 0.4745238095238095\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.45\n",
            "  Validation Loss: 0.70\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.68\n",
            "Acc: 0.5625\tF1: 0.6196969696969696\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.52\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.38\n",
            "Acc: 0.78125\tF1: 0.4\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.43\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.36\n",
            "Acc: 1.0\tF1: 0.75\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.25\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.33\n",
            "Acc: 0.9375\tF1: 0.7333333333333334\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.48\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 0.96875\tF1: 0.7333333333333334\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.85\n",
            "AVG F1: 0.6472727272727272\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.71\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.60\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 0.60\n",
            "Acc: 0.53125\tF1: 0.2\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.51\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.33\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.24\n",
            "Acc: 0.8125\tF1: 0.43333333333333335\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.55\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.51\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.45\n",
            "Acc: 1.0\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.11\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.36\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.11\n",
            "Acc: 0.90625\tF1: 0.7166666666666667\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.85\n",
            "AVG F1: 0.57\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.72\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.61\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.54\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.52\n",
            "Acc: 0.8125\tF1: 0.6089743589743589\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.41\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.21\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.63\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.45\n",
            "Acc: 0.8125\tF1: 0.4606060606060606\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.37\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.16\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.20\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.15\n",
            "Acc: 1.0\tF1: 0.75\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.47\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.67\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.56\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.41\n",
            "Acc: 0.96875\tF1: 0.7333333333333334\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.91875\n",
            "AVG F1: 0.6605827505827506\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 256\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.68\n",
            "Acc: 0.59375\tF1: 0.6196969696969696\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.63\n",
            "Acc: 0.6875\tF1: 0.375\n",
            "  Accuracy: 0.49\n",
            "  Validation Loss: 0.65\n",
            "Acc: 0.5625\tF1: 0.6\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.65\n",
            "Acc: 0.8125\tF1: 0.5923076923076923\n",
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.68\n",
            "Acc: 0.7991071428571428\tF1: 0.6333333333333333\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.6910714285714286\n",
            "AVG F1: 0.5640675990675991\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 256\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.72\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.65\n",
            "Acc: 0.59375\tF1: 0.5506410256410257\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.61\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.51\n",
            "Acc: 0.75\tF1: 0.41515151515151516\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.53\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.56\n",
            "Acc: 0.8125\tF1: 0.6666666666666666\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.24\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.21\n",
            "Acc: 0.875\tF1: 0.7166666666666667\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.39\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.28\n",
            "Acc: 0.8348214285714286\tF1: 0.6083333333333334\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.7732142857142856\n",
            "AVG F1: 0.5914918414918415\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 256\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.69\n",
            "  Accuracy: 0.69\n",
            "  Validation Loss: 0.61\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.45\n",
            "Acc: 0.78125\tF1: 0.5535714285714286\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.49\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.39\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.32\n",
            "Acc: 0.75\tF1: 0.45833333333333337\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.65\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.79\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.91\n",
            "Acc: 0.96875\tF1: 0.7333333333333334\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.05\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.40\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.03\n",
            "Acc: 0.96875\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.89375\n",
            "AVG F1: 0.6490476190476191\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 256\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.55\n",
            "  Validation Loss: 0.67\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.66\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.56\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 0.60\n",
            "Acc: 0.75\tF1: 0.5256410256410257\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.53\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.69\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.61\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.57\n",
            "Acc: 0.4375\tF1: 0.4642857142857143\n",
            "  Accuracy: 0.49\n",
            "  Validation Loss: 0.73\n",
            "  Accuracy: 0.55\n",
            "  Validation Loss: 0.69\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.69\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.72\n",
            "Acc: 0.75\tF1: 0.5506410256410257\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.45\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.51\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.39\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.30\n",
            "Acc: 0.84375\tF1: 0.6642857142857144\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.05\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.28\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.03\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.20\n",
            "Acc: 0.90625\tF1: 0.48333333333333334\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.7375\n",
            "AVG F1: 0.5376373626373627\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 512\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.66\n",
            "Acc: 0.65625\tF1: 0.4583333333333333\n",
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.65\n",
            "Acc: 0.4375\tF1: 0.4642857142857143\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.64\n",
            "Acc: 0.78125\tF1: 0.5666666666666667\n",
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.70\n",
            "Acc: 0.8125\tF1: 0.4476190476190476\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.61\n",
            "Acc: 0.7098214285714286\tF1: 0.38461538461538464\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.6794642857142856\n",
            "AVG F1: 0.46430402930402936\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 512\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.68\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.65\n",
            "Acc: 0.71875\tF1: 0.48461538461538467\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.57\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.52\n",
            "Acc: 0.71875\tF1: 0.2857142857142857\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.54\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.38\n",
            "Acc: 1.0\tF1: 0.75\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.49\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.49\n",
            "Acc: 0.8125\tF1: 0.6976190476190476\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.52\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.77\n",
            "Acc: 0.9375\tF1: 0.7166666666666667\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.8375\n",
            "AVG F1: 0.586923076923077\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 512\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.67\n",
            "  Accuracy: 0.59\n",
            "  Validation Loss: 0.61\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.52\n",
            "Acc: 0.8125\tF1: 0.6089743589743589\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.39\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.29\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.28\n",
            "Acc: 0.84375\tF1: 0.45833333333333337\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.45\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.63\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.83\n",
            "Acc: 1.0\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.03\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "Acc: 0.96875\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.925\n",
            "AVG F1: 0.6634615384615385\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 512\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.78\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.67\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.60\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.64\n",
            "Acc: 0.71875\tF1: 0.5714285714285714\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.56\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.55\n",
            "  Accuracy: 0.64\n",
            "  Validation Loss: 0.97\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.48\n",
            "Acc: 0.65625\tF1: 0.4\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.64\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.54\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.49\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.46\n",
            "Acc: 0.9375\tF1: 0.75\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.58\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.46\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.31\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.34\n",
            "Acc: 0.90625\tF1: 0.7166666666666667\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.34\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.23\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.26\n",
            "Acc: 0.9375\tF1: 0.7166666666666667\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.83125\n",
            "AVG F1: 0.630952380952381\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.62\n",
            "Acc: 0.71875\tF1: 0.483974358974359\n",
            "  Accuracy: 0.70\n",
            "  Validation Loss: 0.64\n",
            "Acc: 0.65625\tF1: 0.4772727272727273\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.60\n",
            "Acc: 0.84375\tF1: 0.6833333333333333\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.58\n",
            "Acc: 0.78125\tF1: 0.5666666666666667\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.56\n",
            "Acc: 0.7991071428571428\tF1: 0.6976190476190476\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.7598214285714285\n",
            "AVG F1: 0.5817732267732267\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.68\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.68\n",
            "Acc: 0.625\tF1: 0.6363636363636364\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.58\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.56\n",
            "Acc: 0.6875\tF1: 0.41515151515151516\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.44\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.39\n",
            "Acc: 0.875\tF1: 0.6833333333333333\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.22\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.20\n",
            "Acc: 0.96875\tF1: 0.75\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.13\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.10\n",
            "Acc: 1.0\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.83125\n",
            "AVG F1: 0.646969696969697\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.66\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.54\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.51\n",
            "Acc: 0.8125\tF1: 0.6309523809523809\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.43\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.30\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.27\n",
            "Acc: 0.84375\tF1: 0.48333333333333334\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.48\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.74\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.71\n",
            "Acc: 0.9375\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.04\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.03\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.03\n",
            "Acc: 0.96875\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 0.9642857142857143\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.9053571428571429\n",
            "AVG F1: 0.6728571428571428\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.66\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 0.59\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.51\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.46\n",
            "Acc: 0.8125\tF1: 0.6517857142857143\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.24\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.35\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.27\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.25\n",
            "Acc: 0.875\tF1: 0.45833333333333337\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.15\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.11\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.39\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.28\n",
            "Acc: 1.0\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.9375\n",
            "AVG F1: 0.6720238095238096\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.65\n",
            "Acc: 0.65625\tF1: 0.458974358974359\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.58\n",
            "Acc: 0.625\tF1: 0.41666666666666663\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.55\n",
            "Acc: 0.8125\tF1: 0.6666666666666666\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.62\n",
            "Acc: 0.84375\tF1: 0.6976190476190476\n",
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.70\n",
            "Acc: 0.8035714285714286\tF1: 0.4666666666666667\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.7482142857142857\n",
            "AVG F1: 0.5413186813186813\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.68\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.68\n",
            "Acc: 0.6875\tF1: 0.5423076923076923\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.55\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.50\n",
            "Acc: 0.71875\tF1: 0.3392857142857143\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.48\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.35\n",
            "Acc: 0.9375\tF1: 0.625\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.27\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.29\n",
            "Acc: 0.875\tF1: 0.7166666666666667\n",
            "  Accuracy: 0.64\n",
            "  Validation Loss: 0.65\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.25\n",
            "Acc: 0.9375\tF1: 0.48333333333333334\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.83125\n",
            "AVG F1: 0.5413186813186813\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.64\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.58\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.57\n",
            "Acc: 0.8125\tF1: 0.6065934065934067\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.40\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.30\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.26\n",
            "Acc: 0.875\tF1: 0.45833333333333337\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 0.70\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.50\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.45\n",
            "Acc: 0.96875\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.07\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.03\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.03\n",
            "Acc: 0.96875\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.925\n",
            "AVG F1: 0.662985347985348\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.59\n",
            "  Validation Loss: 0.69\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.69\n",
            "  Accuracy: 0.64\n",
            "  Validation Loss: 0.64\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.65\n",
            "Acc: 0.6875\tF1: 0.5904761904761905\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.65\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.62\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.43\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.46\n",
            "Acc: 0.875\tF1: 0.45\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.38\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.17\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.27\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.19\n",
            "Acc: 0.96875\tF1: 0.6666666666666666\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.04\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "Acc: 0.96875\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 0.9375\tF1: 0.7166666666666667\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.8875\n",
            "AVG F1: 0.6347619047619049\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 256\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.69\n",
            "Acc: 0.59375\tF1: 0.6363636363636364\n",
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.66\n",
            "Acc: 0.4375\tF1: 0.4642857142857143\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.59\n",
            "Acc: 0.9375\tF1: 0.6666666666666666\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.63\n",
            "Acc: 0.8125\tF1: 0.5952380952380952\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.60\n",
            "Acc: 0.8660714285714286\tF1: 0.48333333333333334\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.7294642857142857\n",
            "AVG F1: 0.5691774891774892\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 256\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.76\n",
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.66\n",
            "Acc: 0.5625\tF1: 0.5367521367521368\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.62\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.54\n",
            "Acc: 0.625\tF1: 0.38095238095238093\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.56\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.56\n",
            "Acc: 0.71875\tF1: 0.6309523809523809\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.45\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.44\n",
            "Acc: 0.8125\tF1: 0.6142857142857142\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.39\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.33\n",
            "Acc: 0.8392857142857143\tF1: 0.4642857142857143\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.7116071428571429\n",
            "AVG F1: 0.5254456654456654\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 256\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.66\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.62\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.54\n",
            "Acc: 0.75\tF1: 0.5285714285714286\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.46\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.32\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.27\n",
            "Acc: 0.8125\tF1: 0.4226190476190476\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.48\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.48\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.41\n",
            "Acc: 1.0\tF1: 0.75\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.10\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.07\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.06\n",
            "Acc: 0.96875\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.90625\n",
            "AVG F1: 0.6402380952380952\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 256\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.68\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.64\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.59\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.56\n",
            "Acc: 0.8125\tF1: 0.6565934065934066\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.34\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.31\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 1.07\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.68\n",
            "Acc: 0.875\tF1: 0.4772727272727273\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.30\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.04\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "Acc: 0.96875\tF1: 0.6666666666666666\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 0.96875\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.925\n",
            "AVG F1: 0.6601065601065601\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 512\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.67\n",
            "Acc: 0.59375\tF1: 0.6142857142857143\n",
            "  Accuracy: 0.64\n",
            "  Validation Loss: 0.62\n",
            "Acc: 0.53125\tF1: 0.45833333333333337\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.52\n",
            "Acc: 0.8125\tF1: 0.6833333333333333\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.49\n",
            "Acc: 0.875\tF1: 0.7166666666666667\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.67\n",
            "Acc: 0.7410714285714286\tF1: 0.4065934065934066\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.7107142857142856\n",
            "AVG F1: 0.5758424908424908\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 512\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.70\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.65\n",
            "Acc: 0.65625\tF1: 0.5892857142857143\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.57\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.54\n",
            "Acc: 0.5\tF1: 0.4642857142857143\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.57\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.51\n",
            "Acc: 0.84375\tF1: 0.7333333333333334\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.41\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.39\n",
            "Acc: 0.8125\tF1: 0.6785714285714286\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.25\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.60\n",
            "Acc: 0.8705357142857143\tF1: 0.6976190476190476\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.7366071428571429\n",
            "AVG F1: 0.6326190476190476\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 512\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.70\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.60\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.60\n",
            "Acc: 0.65625\tF1: 0.32867132867132864\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.41\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.28\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.27\n",
            "Acc: 0.75\tF1: 0.39610389610389607\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 0.78\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.65\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.59\n",
            "Acc: 0.96875\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.06\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.05\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.04\n",
            "Acc: 0.96875\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "Acc: 1.0\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.86875\n",
            "AVG F1: 0.5949550449550449\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 512\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.67\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.63\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.49\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.46\n",
            "Acc: 0.71875\tF1: 0.5065934065934066\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.50\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.56\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.45\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.45\n",
            "Acc: 0.84375\tF1: 0.44166666666666665\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.87\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.33\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.23\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.25\n",
            "Acc: 0.9375\tF1: 0.6666666666666666\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.24\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "Acc: 0.96875\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.89375\n",
            "AVG F1: 0.622985347985348\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 2e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.62\n",
            "Acc: 0.53125\tF1: 0.2919191919191919\n",
            "  Accuracy: 0.60\n",
            "  Validation Loss: 0.64\n",
            "Acc: 0.625\tF1: 0.41666666666666663\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.57\n",
            "Acc: 0.875\tF1: 0.65\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.56\n",
            "Acc: 0.875\tF1: 0.7142857142857143\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.63\n",
            "Acc: 0.7991071428571428\tF1: 0.4642857142857143\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.7410714285714286\n",
            "AVG F1: 0.5074314574314573\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 2e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.69\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.68\n",
            "Acc: 0.65625\tF1: 0.6363636363636364\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.55\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.52\n",
            "Acc: 0.65625\tF1: 0.4\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.48\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.42\n",
            "Acc: 0.84375\tF1: 0.7333333333333334\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.32\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.21\n",
            "Acc: 0.875\tF1: 0.7166666666666667\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.21\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.25\n",
            "Acc: 0.96875\tF1: 0.7333333333333334\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.8\n",
            "AVG F1: 0.6439393939393939\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 2e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.49\n",
            "  Validation Loss: 0.67\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.58\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 0.57\n",
            "Acc: 0.6875\tF1: 0.48461538461538467\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.47\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.38\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.38\n",
            "Acc: 0.78125\tF1: 0.4226190476190476\n",
            "  Accuracy: 0.49\n",
            "  Validation Loss: 0.75\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.68\n",
            "  Accuracy: 0.69\n",
            "  Validation Loss: 0.75\n",
            "Acc: 0.90625\tF1: 0.7166666666666667\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.14\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.14\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.12\n",
            "Acc: 0.9375\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.04\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "Acc: 0.9642857142857143\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.8553571428571429\n",
            "AVG F1: 0.6247802197802198\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 2e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.66\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.60\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.54\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.51\n",
            "Acc: 0.84375\tF1: 0.6708333333333333\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.41\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.40\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.38\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.38\n",
            "Acc: 0.84375\tF1: 0.45833333333333337\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.21\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.22\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.27\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.21\n",
            "Acc: 1.0\tF1: 0.75\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.10\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "Acc: 1.0\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.9375\n",
            "AVG F1: 0.6758333333333334\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 2e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.67\n",
            "Acc: 0.59375\tF1: 0.6333333333333333\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.62\n",
            "Acc: 0.6875\tF1: 0.41666666666666663\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.57\n",
            "Acc: 0.75\tF1: 0.5916666666666667\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.63\n",
            "Acc: 0.875\tF1: 0.7166666666666667\n",
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.63\n",
            "Acc: 0.7723214285714286\tF1: 0.42857142857142855\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.7357142857142857\n",
            "AVG F1: 0.5573809523809524\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 2e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.68\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.67\n",
            "Acc: 0.75\tF1: 0.6089743589743589\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.56\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.56\n",
            "Acc: 0.6875\tF1: 0.3392857142857143\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.39\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.36\n",
            "Acc: 0.9375\tF1: 0.65\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.32\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.29\n",
            "Acc: 0.84375\tF1: 0.6785714285714286\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.39\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.39\n",
            "Acc: 0.96875\tF1: 0.7333333333333334\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.8375\n",
            "AVG F1: 0.602032967032967\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 2e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.66\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.63\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.60\n",
            "Acc: 0.71875\tF1: 0.483974358974359\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.42\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.30\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.32\n",
            "Acc: 0.75\tF1: 0.41515151515151516\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.45\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.55\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.52\n",
            "Acc: 0.96875\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.09\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.09\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.08\n",
            "Acc: 0.96875\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.03\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "Acc: 0.9642857142857143\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.8741071428571429\n",
            "AVG F1: 0.6298251748251749\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 2e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.68\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.67\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.65\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.64\n",
            "Acc: 0.78125\tF1: 0.6619047619047619\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.52\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.44\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.54\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.55\n",
            "Acc: 0.84375\tF1: 0.45\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.19\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.25\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.14\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.19\n",
            "Acc: 0.9375\tF1: 0.625\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.04\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.28\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.24\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.20\n",
            "Acc: 0.96875\tF1: 0.7333333333333334\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.90625\n",
            "AVG F1: 0.644047619047619\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 2e-05\n",
            "EMBEDDING LEN: 256\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.69\n",
            "Acc: 0.59375\tF1: 0.6363636363636364\n",
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.67\n",
            "Acc: 0.4375\tF1: 0.4642857142857143\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.65\n",
            "Acc: 0.8125\tF1: 0.5732600732600732\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.61\n",
            "Acc: 0.75\tF1: 0.6666666666666666\n",
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.60\n",
            "Acc: 0.7410714285714286\tF1: 0.4065934065934066\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.6669642857142857\n",
            "AVG F1: 0.5494338994338995\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 2e-05\n",
            "EMBEDDING LEN: 256\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.68\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.68\n",
            "Acc: 0.59375\tF1: 0.6333333333333333\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.63\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.61\n",
            "Acc: 0.6875\tF1: 0.3392857142857143\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.60\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.57\n",
            "Acc: 0.8125\tF1: 0.6833333333333333\n",
            "  Accuracy: 0.54\n",
            "  Validation Loss: 0.62\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.51\n",
            "Acc: 0.78125\tF1: 0.5923076923076923\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.33\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.26\n",
            "Acc: 0.8705357142857143\tF1: 0.48333333333333334\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.7491071428571429\n",
            "AVG F1: 0.5463186813186813\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 2e-05\n",
            "EMBEDDING LEN: 256\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.65\n",
            "  Validation Loss: 0.66\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 0.63\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.62\n",
            "Acc: 0.6875\tF1: 0.45367132867132864\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.44\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.35\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.36\n",
            "Acc: 0.78125\tF1: 0.39610389610389607\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.44\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.57\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.49\n",
            "Acc: 1.0\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.09\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.08\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.07\n",
            "Acc: 0.90625\tF1: 0.7142857142857143\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.14\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "Acc: 0.9330357142857143\tF1: 0.5\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.8616071428571429\n",
            "AVG F1: 0.5628121878121878\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 2e-05\n",
            "EMBEDDING LEN: 256\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.65\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.64\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.61\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.60\n",
            "Acc: 0.71875\tF1: 0.6131410256410257\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.47\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.33\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.65\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.62\n",
            "Acc: 0.84375\tF1: 0.45\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.27\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.16\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.26\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.09\n",
            "Acc: 0.96875\tF1: 0.6666666666666666\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.07\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.03\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "Acc: 0.96875\tF1: 0.75\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.9\n",
            "AVG F1: 0.6459615384615385\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 2e-05\n",
            "EMBEDDING LEN: 512\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.67\n",
            "Acc: 0.59375\tF1: 0.6363636363636364\n",
            "  Accuracy: 0.64\n",
            "  Validation Loss: 0.63\n",
            "Acc: 0.59375\tF1: 0.4807692307692307\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.54\n",
            "Acc: 0.78125\tF1: 0.5732600732600732\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.60\n",
            "Acc: 0.84375\tF1: 0.6976190476190476\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.64\n",
            "Acc: 0.6741071428571428\tF1: 0.4065934065934066\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.6973214285714285\n",
            "AVG F1: 0.558921078921079\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 2e-05\n",
            "EMBEDDING LEN: 512\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.68\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.68\n",
            "Acc: 0.75\tF1: 0.6309523809523809\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.57\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.52\n",
            "Acc: 0.6875\tF1: 0.43181818181818177\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.52\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.46\n",
            "Acc: 0.8125\tF1: 0.6666666666666666\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.28\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.23\n",
            "Acc: 0.875\tF1: 0.7166666666666667\n",
            "  Accuracy: 0.64\n",
            "  Validation Loss: 0.74\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.32\n",
            "Acc: 0.9642857142857143\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.8178571428571428\n",
            "AVG F1: 0.6392207792207791\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 2e-05\n",
            "EMBEDDING LEN: 512\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.67\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.62\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.61\n",
            "Acc: 0.75\tF1: 0.558974358974359\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.44\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.36\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.35\n",
            "Acc: 0.71875\tF1: 0.39610389610389607\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.52\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 0.72\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.63\n",
            "Acc: 0.9375\tF1: 0.75\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.35\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.09\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.07\n",
            "Acc: 0.9375\tF1: 0.7333333333333334\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.03\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "Acc: 0.9642857142857143\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.8616071428571429\n",
            "AVG F1: 0.6376823176823176\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 8\n",
            "LEARNING RATE: 2e-05\n",
            "EMBEDDING LEN: 512\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.63\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.63\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.61\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.60\n",
            "Acc: 0.65625\tF1: 0.5923076923076923\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.47\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.60\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.71\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.71\n",
            "Acc: 0.75\tF1: 0.43333333333333335\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.44\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.19\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.31\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.27\n",
            "Acc: 0.96875\tF1: 0.6666666666666666\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.04\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.04\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.04\n",
            "Acc: 0.96875\tF1: 0.75\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.25\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 0.75\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.86875\n",
            "AVG F1: 0.6384615384615385\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.66\n",
            "Acc: 0.75\tF1: 0.7142857142857143\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.60\n",
            "Acc: 0.625\tF1: 0.36363636363636365\n",
            "  Accuracy: 0.55\n",
            "  Validation Loss: 0.64\n",
            "Acc: 0.65625\tF1: 0.6333333333333333\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.36\n",
            "Acc: 0.8125\tF1: 0.7060931899641577\n",
            "  Accuracy: 0.64\n",
            "  Validation Loss: 0.67\n",
            "Acc: 0.8333333333333333\tF1: 0.6428571428571428\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.7354166666666667\n",
            "AVG F1: 0.6120411488153423\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.66\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.66\n",
            "Acc: 0.59375\tF1: 0.6431372549019608\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.49\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.39\n",
            "Acc: 0.6875\tF1: 0.34782608695652173\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.45\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.36\n",
            "Acc: 0.9375\tF1: 0.9666666666666667\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.23\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.18\n",
            "Acc: 0.90625\tF1: 0.8172043010752688\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.33\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "Acc: 0.9375\tF1: 0.9666666666666667\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.8125\n",
            "AVG F1: 0.748300195253417\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.70\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.65\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.51\n",
            "Acc: 0.625\tF1: 0.3333333333333333\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.47\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.30\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.37\n",
            "Acc: 0.71875\tF1: 0.4615384615384615\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.53\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.72\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.81\n",
            "Acc: 0.9375\tF1: 0.8333333333333333\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.12\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.18\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.20\n",
            "Acc: 0.90625\tF1: 0.8172043010752688\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 0.9666666666666667\tF1: 0.8333333333333333\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.8308333333333333\n",
            "AVG F1: 0.655748552522746\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.72\n",
            "  Accuracy: 0.49\n",
            "  Validation Loss: 0.69\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.69\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.69\n",
            "Acc: 0.59375\tF1: 0.6578947368421053\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.43\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.33\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.29\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.42\n",
            "Acc: 0.6875\tF1: 0.36363636363636365\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.32\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.52\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.85\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.83\n",
            "Acc: 0.90625\tF1: 0.8666666666666667\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.35\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.08\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.12\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.28\n",
            "Acc: 1.0\tF1: 1.0\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.91\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 1.0\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.8375\n",
            "AVG F1: 0.7776395534290271\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.66\n",
            "Acc: 0.5\tF1: 0.3611111111111111\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.57\n",
            "Acc: 0.65625\tF1: 0.391304347826087\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.58\n",
            "Acc: 0.75\tF1: 0.6666666666666667\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.57\n",
            "Acc: 0.84375\tF1: 0.7816091954022988\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.73\n",
            "Acc: 0.8375\tF1: 0.4666666666666667\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.7175\n",
            "AVG F1: 0.5334715975345661\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.45\n",
            "  Validation Loss: 0.70\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.68\n",
            "Acc: 0.5625\tF1: 0.6417657045840408\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.52\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.38\n",
            "Acc: 0.78125\tF1: 0.41666666666666663\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.43\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.36\n",
            "Acc: 1.0\tF1: 1.0\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.25\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.33\n",
            "Acc: 0.9375\tF1: 0.8838709677419355\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.48\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 0.96875\tF1: 0.9838709677419355\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.85\n",
            "AVG F1: 0.7852348613469157\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.71\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.60\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 0.60\n",
            "Acc: 0.53125\tF1: 0.2\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.51\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.33\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.24\n",
            "Acc: 0.8125\tF1: 0.44\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.55\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.51\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.45\n",
            "Acc: 1.0\tF1: 1.0\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.11\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.36\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.11\n",
            "Acc: 0.90625\tF1: 0.8666666666666667\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 1.0\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.85\n",
            "AVG F1: 0.7013333333333334\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.72\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.61\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.54\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.52\n",
            "Acc: 0.8125\tF1: 0.7339901477832513\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.41\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.21\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.63\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.45\n",
            "Acc: 0.8125\tF1: 0.4615384615384615\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.37\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.16\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.20\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.15\n",
            "Acc: 1.0\tF1: 1.0\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.47\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.67\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.56\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.41\n",
            "Acc: 0.96875\tF1: 0.9838709677419355\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 1.0\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.91875\n",
            "AVG F1: 0.8358799154127297\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 256\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.68\n",
            "Acc: 0.59375\tF1: 0.6505376344086022\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.63\n",
            "Acc: 0.6875\tF1: 0.41666666666666663\n",
            "  Accuracy: 0.49\n",
            "  Validation Loss: 0.65\n",
            "Acc: 0.5625\tF1: 0.6111111111111112\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.65\n",
            "Acc: 0.8125\tF1: 0.6785714285714286\n",
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.68\n",
            "Acc: 0.8041666666666667\tF1: 0.6333333333333333\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.6920833333333334\n",
            "AVG F1: 0.5980440348182283\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 256\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.72\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.65\n",
            "Acc: 0.59375\tF1: 0.5824175824175823\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.61\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.51\n",
            "Acc: 0.75\tF1: 0.4230769230769231\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.53\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.56\n",
            "Acc: 0.8125\tF1: 0.7\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.24\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.21\n",
            "Acc: 0.875\tF1: 0.8\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.39\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.28\n",
            "Acc: 0.8354166666666667\tF1: 0.6505376344086022\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.7733333333333333\n",
            "AVG F1: 0.6312064279806215\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 256\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.69\n",
            "  Accuracy: 0.69\n",
            "  Validation Loss: 0.61\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.45\n",
            "Acc: 0.78125\tF1: 0.6285714285714286\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.49\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.39\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.32\n",
            "Acc: 0.75\tF1: 0.4642857142857143\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.65\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.79\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.91\n",
            "Acc: 0.96875\tF1: 0.9838709677419355\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.05\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.40\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.03\n",
            "Acc: 0.96875\tF1: 0.9\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 1.0\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.89375\n",
            "AVG F1: 0.7953456221198156\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 256\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.55\n",
            "  Validation Loss: 0.67\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.66\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.56\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 0.60\n",
            "Acc: 0.75\tF1: 0.5952380952380952\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.53\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.69\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.61\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.57\n",
            "Acc: 0.4375\tF1: 0.4666666666666667\n",
            "  Accuracy: 0.49\n",
            "  Validation Loss: 0.73\n",
            "  Accuracy: 0.55\n",
            "  Validation Loss: 0.69\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.69\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.72\n",
            "Acc: 0.75\tF1: 0.5952380952380952\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.45\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.51\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.39\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.30\n",
            "Acc: 0.84375\tF1: 0.7523809523809524\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.05\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.28\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.03\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.20\n",
            "Acc: 0.9020833333333333\tF1: 0.4838709677419355\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.7366666666666667\n",
            "AVG F1: 0.5786789554531491\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 512\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.66\n",
            "Acc: 0.65625\tF1: 0.5333333333333333\n",
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.65\n",
            "Acc: 0.4375\tF1: 0.4666666666666667\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.64\n",
            "Acc: 0.78125\tF1: 0.6574074074074074\n",
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.70\n",
            "Acc: 0.8125\tF1: 0.4482758620689655\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.61\n",
            "Acc: 0.7125\tF1: 0.38461538461538464\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.6799999999999999\n",
            "AVG F1: 0.4980597308183515\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 512\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.68\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.65\n",
            "Acc: 0.71875\tF1: 0.5846153846153846\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.57\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.52\n",
            "Acc: 0.71875\tF1: 0.3333333333333333\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.54\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.38\n",
            "Acc: 1.0\tF1: 1.0\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.49\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.49\n",
            "Acc: 0.8125\tF1: 0.7339901477832513\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.52\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.77\n",
            "Acc: 0.9375\tF1: 0.9666666666666667\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.8375\n",
            "AVG F1: 0.7237211064797272\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 512\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.67\n",
            "  Accuracy: 0.59\n",
            "  Validation Loss: 0.61\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.52\n",
            "Acc: 0.8125\tF1: 0.7339901477832513\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.39\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.29\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.28\n",
            "Acc: 0.84375\tF1: 0.4642857142857143\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.45\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.63\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.83\n",
            "Acc: 1.0\tF1: 1.0\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.03\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "Acc: 0.96875\tF1: 0.9\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 1.0\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.925\n",
            "AVG F1: 0.8196551724137932\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 5e-05\n",
            "EMBEDDING LEN: 512\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.78\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.67\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.60\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.64\n",
            "Acc: 0.71875\tF1: 0.6507936507936507\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.56\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.55\n",
            "  Accuracy: 0.64\n",
            "  Validation Loss: 0.97\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.48\n",
            "Acc: 0.65625\tF1: 0.4230769230769231\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.64\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.54\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.49\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.46\n",
            "Acc: 0.9375\tF1: 0.8333333333333333\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.58\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.46\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.31\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.34\n",
            "Acc: 0.90625\tF1: 0.8666666666666667\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.34\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.23\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.26\n",
            "Acc: 0.9375\tF1: 0.9666666666666667\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.83125\n",
            "AVG F1: 0.7481074481074481\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.62\n",
            "Acc: 0.71875\tF1: 0.61\n",
            "  Accuracy: 0.70\n",
            "  Validation Loss: 0.64\n",
            "Acc: 0.65625\tF1: 0.4814814814814815\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.60\n",
            "Acc: 0.84375\tF1: 0.7338709677419355\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.58\n",
            "Acc: 0.78125\tF1: 0.6574074074074074\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.56\n",
            "Acc: 0.80625\tF1: 0.6482758620689655\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.76125\n",
            "AVG F1: 0.626207143739958\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.68\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.68\n",
            "Acc: 0.625\tF1: 0.6666666666666667\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.58\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.56\n",
            "Acc: 0.6875\tF1: 0.4230769230769231\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.44\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.39\n",
            "Acc: 0.875\tF1: 0.7695852534562213\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.22\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.20\n",
            "Acc: 0.96875\tF1: 0.9\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.13\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.10\n",
            "Acc: 1.0\tF1: 1.0\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.83125\n",
            "AVG F1: 0.7518657686399622\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.66\n",
            "  Accuracy: 0.75\n",
            "  Validation Loss: 0.54\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.51\n",
            "Acc: 0.8125\tF1: 0.7166666666666667\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.43\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.30\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.27\n",
            "Acc: 0.84375\tF1: 0.4814814814814815\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.48\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.74\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.71\n",
            "Acc: 0.9375\tF1: 0.8333333333333333\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.04\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.03\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.03\n",
            "Acc: 0.96875\tF1: 0.9\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 0.9666666666666667\tF1: 0.8333333333333333\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.9058333333333334\n",
            "AVG F1: 0.7529629629629631\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 64\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.66\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 0.59\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.51\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.46\n",
            "Acc: 0.8125\tF1: 0.7666666666666666\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.24\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.35\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.27\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.25\n",
            "Acc: 0.875\tF1: 0.4642857142857143\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.15\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.11\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.39\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.28\n",
            "Acc: 1.0\tF1: 1.0\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 1.0\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 1.0\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.9375\n",
            "AVG F1: 0.8461904761904762\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.65\n",
            "Acc: 0.65625\tF1: 0.5266666666666666\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.58\n",
            "Acc: 0.625\tF1: 0.44\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.55\n",
            "Acc: 0.8125\tF1: 0.7\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.62\n",
            "Acc: 0.84375\tF1: 0.7816091954022988\n",
            "  Accuracy: 0.57\n",
            "  Validation Loss: 0.70\n",
            "Acc: 0.8041666666666667\tF1: 0.4666666666666667\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.7483333333333333\n",
            "AVG F1: 0.5829885057471265\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.68\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.68\n",
            "Acc: 0.6875\tF1: 0.5593869731800767\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.55\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.50\n",
            "Acc: 0.71875\tF1: 0.36363636363636365\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.48\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.35\n",
            "Acc: 0.9375\tF1: 0.75\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.27\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.29\n",
            "Acc: 0.875\tF1: 0.8\n",
            "  Accuracy: 0.64\n",
            "  Validation Loss: 0.65\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.25\n",
            "Acc: 0.9354166666666667\tF1: 0.4838709677419355\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.8308333333333333\n",
            "AVG F1: 0.5913788609116752\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.64\n",
            "  Accuracy: 0.71\n",
            "  Validation Loss: 0.58\n",
            "  Accuracy: 0.61\n",
            "  Validation Loss: 0.57\n",
            "Acc: 0.8125\tF1: 0.8074074074074074\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.40\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.30\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.26\n",
            "Acc: 0.875\tF1: 0.4642857142857143\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 0.70\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.50\n",
            "  Accuracy: 0.84\n",
            "  Validation Loss: 0.45\n",
            "Acc: 0.96875\tF1: 0.9\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.07\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.03\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.03\n",
            "Acc: 0.96875\tF1: 0.9\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.00\n",
            "Acc: 1.0\tF1: 1.0\n",
            "\n",
            "\n",
            "\n",
            "AVG Acc: 0.925\n",
            "AVG F1: 0.8143386243386244\n",
            "SEED: 0\n",
            "MODEL: Bert\n",
            "BATCH SIZE TR: 8\n",
            "BATCH SIZE TS: 16\n",
            "LEARNING RATE: 3e-05\n",
            "EMBEDDING LEN: 128\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.59\n",
            "  Validation Loss: 0.69\n",
            "  Accuracy: 0.51\n",
            "  Validation Loss: 0.69\n",
            "  Accuracy: 0.64\n",
            "  Validation Loss: 0.64\n",
            "  Accuracy: 0.74\n",
            "  Validation Loss: 0.65\n",
            "Acc: 0.6875\tF1: 0.6300940438871474\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.65\n",
            "  Accuracy: 0.68\n",
            "  Validation Loss: 0.62\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.43\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.46\n",
            "Acc: 0.875\tF1: 0.4615384615384615\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.38\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.17\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.27\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.19\n",
            "Acc: 0.96875\tF1: 0.8333333333333333\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.04\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.02\n",
            "  Accuracy: 1.00\n",
            "  Validation Loss: 0.01\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}